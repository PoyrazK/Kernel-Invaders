{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ¡ Ä°stanbul Emlak YatÄ±rÄ±m DanÄ±ÅŸmanÄ±\n",
                "## AI SPARK HACKATHON - Model EÄŸitim Notebook\n",
                "\n",
                "Bu notebook, ev fiyat tahmin modelinin eÄŸitim sÃ¼recini adÄ±m adÄ±m gÃ¶stermektedir."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. KÃ¼tÃ¼phanelerin YÃ¼klenmesi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
                "from sklearn.metrics import r2_score, mean_squared_error\n",
                "import lightgbm as lgb\n",
                "import joblib\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"KÃ¼tÃ¼phaneler yÃ¼klendi âœ…\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Veri YÃ¼kleme ve Ä°nceleme"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Veriyi yÃ¼kle\n",
                "df = pd.read_csv('../hackathon_train_set.csv', sep=';')\n",
                "\n",
                "print(f\"Toplam kayÄ±t: {len(df)}\")\n",
                "print(f\"Toplam Ã¶zellik: {len(df.columns)}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hedef deÄŸiÅŸken inceleme\n",
                "print(\"Price sÃ¼tunu Ã¶rnekleri:\")\n",
                "df['Price'].head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Veri Temizleme (Data Cleaning)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_price(price_str):\n",
                "    \"\"\"Fiyat stringini sayÄ±sala Ã§evirir.\"\"\"\n",
                "    if pd.isna(price_str):\n",
                "        return np.nan\n",
                "    clean_str = str(price_str).replace(' TL', '').replace('.', '').strip()\n",
                "    try:\n",
                "        return int(clean_str)\n",
                "    except ValueError:\n",
                "        return np.nan\n",
                "\n",
                "df['Price'] = df['Price'].apply(clean_price)\n",
                "df = df.dropna(subset=['Price'])\n",
                "\n",
                "print(f\"Temizleme sonrasÄ± kayÄ±t: {len(df)}\")\n",
                "print(f\"\\nFiyat istatistikleri:\")\n",
                "df['Price'].describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_rooms(room_str):\n",
                "    \"\"\"'3+1' formatÄ±nÄ± toplam odaya Ã§evirir.\"\"\"\n",
                "    if pd.isna(room_str):\n",
                "        return np.nan\n",
                "    try:\n",
                "        parts = str(room_str).split('+')\n",
                "        return sum(int(p) for p in parts)\n",
                "    except:\n",
                "        if \"StÃ¼dyo\" in str(room_str):\n",
                "            return 1\n",
                "        return np.nan\n",
                "\n",
                "def clean_age(age_str):\n",
                "    \"\"\"Bina yaÅŸÄ± aralÄ±klarÄ±nÄ± sayÄ±sala Ã§evirir.\"\"\"\n",
                "    if pd.isna(age_str):\n",
                "        return np.nan\n",
                "    s = str(age_str)\n",
                "    if \"0\" == s: return 0\n",
                "    if \"1-5\" in s: return 3\n",
                "    if \"5-10\" in s: return 7.5\n",
                "    if \"11-15\" in s: return 13\n",
                "    if \"16-20\" in s: return 18\n",
                "    if \"21-25\" in s: return 23\n",
                "    if \"26-30\" in s: return 28\n",
                "    if \"31 ve Ã¼zeri\" in s: return 35\n",
                "    try:\n",
                "        return int(s)\n",
                "    except:\n",
                "        return np.nan\n",
                "\n",
                "def clean_balcony(val):\n",
                "    if pd.isna(val): return 0\n",
                "    if 'Available' in str(val) or 'Yes' in str(val): return 1\n",
                "    return 0"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# m2 temizleme\n",
                "for col in ['mÂ² (Gross)', 'mÂ² (Net)']:\n",
                "    if col in df.columns:\n",
                "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
                "\n",
                "# Oda sayÄ±sÄ±\n",
                "df['Rooms_Num'] = df['Number of rooms'].apply(clean_rooms)\n",
                "\n",
                "# Bina yaÅŸÄ±\n",
                "df['Age_Num'] = df['Building Age'].apply(clean_age)\n",
                "\n",
                "# Oda baÅŸÄ±na m2\n",
                "df['Room_Size_Ratio'] = df['mÂ² (Net)'] / df['Rooms_Num'].replace(0, 1)\n",
                "\n",
                "# Balkon\n",
                "df['Balcony_Bool'] = df['Balcony'].apply(clean_balcony)\n",
                "\n",
                "# SayÄ±sal dÃ¶nÃ¼ÅŸÃ¼mler\n",
                "for col in ['Number of bathrooms', 'Number of floors']:\n",
                "    if col in df.columns:\n",
                "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
                "\n",
                "print(\"Feature engineering tamamlandÄ± âœ…\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# KullanÄ±lacak Ã¶zellikleri seÃ§\n",
                "keep_cols = [\n",
                "    'Price', 'District', 'Neighborhood', \n",
                "    'mÂ² (Net)', 'Rooms_Num', 'Age_Num', 'Room_Size_Ratio',\n",
                "    'Floor location', 'Heating', 'Number of bathrooms', 'Number of floors',\n",
                "    'Balcony_Bool', 'Elevator', 'Parking Lot', 'Security'\n",
                "]\n",
                "\n",
                "df_model = df[keep_cols].copy()\n",
                "\n",
                "# Eksik deÄŸerleri doldur\n",
                "binary_cols = ['Balcony_Bool', 'Elevator', 'Parking Lot', 'Security']\n",
                "for col in binary_cols:\n",
                "    df_model[col] = pd.to_numeric(df_model[col], errors='coerce').fillna(0)\n",
                "\n",
                "num_cols = ['mÂ² (Net)', 'Rooms_Num', 'Age_Num', 'Room_Size_Ratio', 'Number of bathrooms', 'Number of floors']\n",
                "for col in num_cols:\n",
                "    df_model[col] = df_model[col].fillna(df_model[col].median())\n",
                "\n",
                "cat_cols = ['District', 'Neighborhood', 'Floor location', 'Heating']\n",
                "df_model[cat_cols] = df_model[cat_cols].fillna(\"Unknown\")\n",
                "\n",
                "print(f\"Final veri boyutu: {df_model.shape}\")\n",
                "df_model.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Outlier Temizleme"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# %1 ve %99 dilimler arasÄ± verileri tut\n",
                "lower_bound = df_model['Price'].quantile(0.01)\n",
                "upper_bound = df_model['Price'].quantile(0.99)\n",
                "\n",
                "print(f\"Alt sÄ±nÄ±r: {lower_bound:,.0f} TL\")\n",
                "print(f\"Ãœst sÄ±nÄ±r: {upper_bound:,.0f} TL\")\n",
                "\n",
                "df_clean = df_model[(df_model['Price'] >= lower_bound) & (df_model['Price'] <= upper_bound)]\n",
                "print(f\"\\nOutlier temizliÄŸi sonrasÄ±: {len(df_clean)} kayÄ±t ({len(df_model) - len(df_clean)} silindi)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Target Encoding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class TargetEncoder:\n",
                "    \"\"\"Kategorik deÄŸiÅŸkenleri hedef deÄŸiÅŸkenin ortalamasÄ± ile encode eder.\"\"\"\n",
                "    \n",
                "    def __init__(self, cols):\n",
                "        self.cols = cols\n",
                "        self.mapping = {}\n",
                "    \n",
                "    def fit(self, X, y):\n",
                "        df = X.copy()\n",
                "        df['_target'] = y.values\n",
                "        \n",
                "        global_mean = y.mean()\n",
                "        \n",
                "        for col in self.cols:\n",
                "            means = df.groupby(col)['_target'].mean()\n",
                "            self.mapping[col] = means.to_dict()\n",
                "            self.mapping[col]['__global__'] = global_mean\n",
                "        \n",
                "        return self\n",
                "    \n",
                "    def transform(self, X):\n",
                "        df = X.copy()\n",
                "        for col in self.cols:\n",
                "            global_mean = self.mapping[col]['__global__']\n",
                "            df[col] = df[col].map(self.mapping[col]).fillna(global_mean)\n",
                "        return df\n",
                "\n",
                "print(\"Target Encoder sÄ±nÄ±fÄ± tanÄ±mlandÄ± âœ…\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Model EÄŸitimi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Veriyi ayÄ±r\n",
                "X = df_clean.drop(columns=['Price'])\n",
                "y = df_clean['Price']\n",
                "\n",
                "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"EÄŸitim seti: {len(X_train)} kayÄ±t\")\n",
                "print(f\"Validasyon seti: {len(X_val)} kayÄ±t\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Target Encoding uygula\n",
                "encoder = TargetEncoder(cols=['District', 'Neighborhood'])\n",
                "encoder.fit(X_train, y_train)\n",
                "\n",
                "X_train_enc = encoder.transform(X_train)\n",
                "X_val_enc = encoder.transform(X_val)\n",
                "\n",
                "print(\"Target Encoding uygulandÄ± âœ…\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocessor\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['Floor location', 'Heating'])\n",
                "    ],\n",
                "    remainder='passthrough'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LightGBM modeli (Tuned parametreler)\n",
                "lgb_model = Pipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('regressor', lgb.LGBMRegressor(\n",
                "        n_estimators=700,\n",
                "        max_depth=-1,\n",
                "        learning_rate=0.05,\n",
                "        num_leaves=50,\n",
                "        subsample=0.9,\n",
                "        colsample_bytree=0.7,\n",
                "        min_child_samples=10,\n",
                "        reg_alpha=0.1,\n",
                "        reg_lambda=2,\n",
                "        random_state=42,\n",
                "        n_jobs=-1,\n",
                "        verbose=-1\n",
                "    ))\n",
                "])\n",
                "\n",
                "print(\"LightGBM modeli eÄŸitiliyor...\")\n",
                "lgb_model.fit(X_train_enc, y_train)\n",
                "print(\"EÄŸitim tamamlandÄ± âœ…\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Model DeÄŸerlendirme"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tahmin\n",
                "y_pred = lgb_model.predict(X_val_enc)\n",
                "\n",
                "# Metrikler\n",
                "r2 = r2_score(y_val, y_pred)\n",
                "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
                "mape = np.mean(np.abs((y_val - y_pred) / y_val)) * 100\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"ðŸ“Š MODEL PERFORMANSI (Validasyon Seti)\")\n",
                "print(\"=\"*50)\n",
                "print(f\"RÂ² Score: {r2:.4f}\")\n",
                "print(f\"RMSE: {rmse:,.0f} TL\")\n",
                "print(f\"MAPE: {mape:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Model Kaydetme"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model ve encoder'Ä± kaydet\n",
                "joblib.dump(lgb_model, '../models/model.pkl')\n",
                "joblib.dump(encoder, '../models/target_encoder.pkl')\n",
                "\n",
                "# Ä°ÅŸlenmiÅŸ veriyi kaydet (arayÃ¼z iÃ§in)\n",
                "df_clean.to_pickle('../data/processed_data.pkl')\n",
                "\n",
                "print(\"Model ve veriler kaydedildi âœ…\")\n",
                "print(\"  â†’ models/model.pkl\")\n",
                "print(\"  â†’ models/target_encoder.pkl\")\n",
                "print(\"  â†’ data/processed_data.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Ã–rnek Tahmin"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ã–rnek bir ev iÃ§in tahmin\n",
                "sample_house = pd.DataFrame({\n",
                "    'District': ['KadÄ±kÃ¶y'],\n",
                "    'Neighborhood': ['CaferaÄŸa Mh.'],\n",
                "    'mÂ² (Net)': [120],\n",
                "    'Rooms_Num': [4],\n",
                "    'Age_Num': [10],\n",
                "    'Floor location': ['High Rise'],\n",
                "    'Heating': ['Natural Gas (Combi)'],\n",
                "    'Number of bathrooms': [2],\n",
                "    'Number of floors': [8],\n",
                "    'Balcony_Bool': [1],\n",
                "    'Elevator': [1],\n",
                "    'Parking Lot': [1],\n",
                "    'Security': [1],\n",
                "    'Room_Size_Ratio': [30]\n",
                "})\n",
                "\n",
                "sample_enc = encoder.transform(sample_house)\n",
                "predicted_price = lgb_model.predict(sample_enc)[0]\n",
                "\n",
                "print(\"ðŸ  Ã–rnek Ev Tahmini\")\n",
                "print(\"=\"*40)\n",
                "print(f\"Konum: KadÄ±kÃ¶y, CaferaÄŸa\")\n",
                "print(f\"Alan: 120 mÂ², 4 Oda\")\n",
                "print(f\"Ã–zellikler: AsansÃ¶r, Otopark, GÃ¼venlik\")\n",
                "print(f\"\\nðŸ’° Tahmin Edilen DeÄŸer: {predicted_price:,.0f} TL\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸŽ¯ SonuÃ§\n",
                "\n",
                "Bu notebook'ta:\n",
                "1. Veri temizleme ve feature engineering yapÄ±ldÄ±\n",
                "2. Target Encoding ile kategorik deÄŸiÅŸkenler dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼\n",
                "3. LightGBM modeli hyperparameter tuning ile eÄŸitildi\n",
                "4. Model **RÂ² = 0.8115** baÅŸarÄ± oranÄ± ile kaydedildi\n",
                "\n",
                "Model artÄ±k Streamlit arayÃ¼zÃ¼ ile kullanÄ±lmaya hazÄ±r!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}